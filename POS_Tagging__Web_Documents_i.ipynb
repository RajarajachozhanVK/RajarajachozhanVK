{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPRooeLmN4lFA1zVlhNNin",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RajarajachozhanVK/RajarajachozhanVK/blob/main/POS_Tagging__Web_Documents_i.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aim: To build POS tagging for unstructured Web documents\n",
        "1. Introduction\n",
        "Constructing a mathematical model for POS tagging specifically for web documents involves adapting traditional POS tagging approaches to\n",
        "handle the characteristics and challenges of web content, which often includes informal language, HTML tags, and diverse writing styles. Here's\n",
        "how you can formulate such a model:\n",
        "1.1 Define Variables and Parameters\n",
        "+ Observations (Words): W = (w1, ws, ..., w,), where w; represents the i-th word in the sequence extracted from a web document.\n",
        " Hidden States (POS tags): T'= (t,, 1y, . . . ,t, ), where t; represents the POS tag corresponding to w;\n",
        "1.2 Model Assumptions\n",
        "Given the nature of web documents, additional assumptions may include:\n",
        "« HTML Tags: Handling and potentially ignoring or treating HTML tags appropriately.\n",
        "« Informal Language: Accommodating informal language and text found in comments, forums, social media, etc.\n",
        "« Contextual Information: Incorporating contextual cues from surrounding text and links.\n",
        "1.3 Transition and Emission Probabilities\n",
        "Similar to a traditional POS tagging model:\n",
        "« Transition Probabilities: P(t; | t; ;) - Probability of transitioning to POS tag ¢; given t;\n",
        "+ Emission Probabi s: P(w; | t;) - Probability of observing word w; given its POS tag ¢;.\n",
        "1.4 Handling HTML Tags\n",
        "Web documents often contain HTML tags that are not part of the natural language text but are crucial for understanding the structure and\n",
        "context.\n",
        "« Preprocessing: Before POS tagging, remove or appropriately handle HTML tags to avoid misinterpretation o errors in tagging.\n",
        "1.5 Mathematical Formulation\n",
        "The joint probability of a sequence of words and their POS tags can be expressed as:\n",
        "P(T,W) = P(t:) - T}y Plt | 1) - T Plwi | &)\n",
        "Where:\n",
        "« P(t,) is the initial state probability distribution.\n",
        "« P(t; | t; 1) are the transition probabilities.\n",
        "« P(w; | t;) are the emission probabilities.\n",
        "1.6 Implementation Considerations\n",
        "« Tokenization: Splitting the web document into words or tokens, considering HTML tags and their potential impact on text segmentation.\n",
        "« Feature Engineering: Extract relevant features such as word context, surrounding HTML structure, and potentially links and metadata.\n",
        "+ Model Selection: Choose an appropriate model (e.g., HMM, CRF, neural network-based models) based on the complexity and specific\n",
        "requirements of web document POS tagging.\n",
        "1.7 Example Application: Handling Informal Language and HTML Tags\n",
        "Consider a scenario where a web document includes comments and HTML tags. Your model might:\n",
        "« Ignore HTML tags during the tagging process.\n",
        "« Use additional features like user-generated content characteristics (e.g., emoji usage, abbreviations) to improve tagging accuracy.\n"
      ],
      "metadata": {
        "id": "pW5Xd6ZRvENj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayMorJl8tjIA",
        "outputId": "e7f80881-4332-479e-b35c-d0ae8f8767b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Example', 'NNP')\n",
            "('Domain', 'NNP')\n",
            "('Example', 'NNP')\n",
            "('Domain', 'NNP')\n",
            "('This', 'DT')\n",
            "('domain', 'NN')\n",
            "('is', 'VBZ')\n",
            "('for', 'IN')\n",
            "('use', 'NN')\n",
            "('in', 'IN')\n",
            "('illustrative', 'JJ')\n",
            "('examples', 'NNS')\n",
            "('in', 'IN')\n",
            "('documents', 'NNS')\n",
            "('.', '.')\n",
            "('You', 'PRP')\n",
            "('may', 'MD')\n",
            "('use', 'VB')\n",
            "('this', 'DT')\n",
            "('domain', 'NN')\n",
            "('in', 'IN')\n",
            "('literature', 'NN')\n",
            "('without', 'IN')\n",
            "('prior', 'JJ')\n",
            "('coordination', 'NN')\n",
            "('or', 'CC')\n",
            "('asking', 'VBG')\n",
            "('for', 'IN')\n",
            "('permission', 'NN')\n",
            "('.', '.')\n",
            "('More', 'JJR')\n",
            "('information', 'NN')\n",
            "('...', ':')\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "\n",
        "# Download NLTK resources (if not already downloaded)\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Create a function to fetch web content and parse it using BeautifulSoup\n",
        "def fetch_and_parse(url):\n",
        "    \"\"\"Fetches content from a URL and parses the text using BeautifulSoup.\"\"\"\n",
        "    response = requests.get(url)  # Fetch web page content\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')  # Parse HTML content\n",
        "    text = soup.get_text()  # Extract visible text from parsed HTML\n",
        "    return text\n",
        "\n",
        "# Create a function to tokenize the text and perform POS tagging using NLTK\n",
        "def pos_tagging(text):\n",
        "    \"\"\"Performs Part-of-Speech (POS) tagging on the provided text.\"\"\"\n",
        "    tokens = word_tokenize(text)  # Tokenize the text into words\n",
        "    tagged_tokens = pos_tag(tokens)  # Perform POS tagging\n",
        "    return tagged_tokens\n",
        "\n",
        "# Combine the functions to fetch a web page, parse its content, and perform POS tagging\n",
        "if __name__ == \"__main__\":\n",
        "    url = \"http://example.com\"  # Replace with the URL of the web document to process\n",
        "    text = fetch_and_parse(url)  # Fetch and parse the text content from the URL\n",
        "    tagged_tokens = pos_tagging(text)  # Perform POS tagging on the extracted text\n",
        "\n",
        "    # Print out the POS tagged tokens\n",
        "    for token in tagged_tokens:\n",
        "        print(token)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_and_parse(url):\n",
        "    \"\"\"Fetches content from a URL and parses the text using BeautifulSoup.\"\"\"\n",
        "    response = requests.get(url)  # Fetch web page content\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')  # Parse HTML content\n",
        "    text = soup.get_text()  # Extract visible text from parsed HTML\n",
        "    return text"
      ],
      "metadata": {
        "id": "AjNy1MZQw9UM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pos_tagging(text):\n",
        "    \"\"\"Performs Part-of-Speech (POS) tagging on the provided text.\"\"\"\n",
        "    tokens = word_tokenize(text)  # Tokenize the text into words\n",
        "    tagged_tokens = pos_tag(tokens)  # Perform POS tagging\n",
        "    return tagged_tokens"
      ],
      "metadata": {
        "id": "k1_2DuW9xABS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    url = \"http://example.com\"  # Replace with the URL of the web document to process\n",
        "    text = fetch_and_parse(url)  # Fetch and parse the text content from the URL\n",
        "    tagged_tokens = pos_tagging(text)  # Perform POS tagging on the extracted text\n",
        "    # Print out the POS tagged tokens\n",
        "    for token in tagged_tokens:\n",
        "        print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZnCYiEuxC6G",
        "outputId": "393b0d3b-3523-4e8e-aff9-2e116b6d7237"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Example', 'NNP')\n",
            "('Domain', 'NNP')\n",
            "('Example', 'NNP')\n",
            "('Domain', 'NNP')\n",
            "('This', 'DT')\n",
            "('domain', 'NN')\n",
            "('is', 'VBZ')\n",
            "('for', 'IN')\n",
            "('use', 'NN')\n",
            "('in', 'IN')\n",
            "('illustrative', 'JJ')\n",
            "('examples', 'NNS')\n",
            "('in', 'IN')\n",
            "('documents', 'NNS')\n",
            "('.', '.')\n",
            "('You', 'PRP')\n",
            "('may', 'MD')\n",
            "('use', 'VB')\n",
            "('this', 'DT')\n",
            "('domain', 'NN')\n",
            "('in', 'IN')\n",
            "('literature', 'NN')\n",
            "('without', 'IN')\n",
            "('prior', 'JJ')\n",
            "('coordination', 'NN')\n",
            "('or', 'CC')\n",
            "('asking', 'VBG')\n",
            "('for', 'IN')\n",
            "('permission', 'NN')\n",
            "('.', '.')\n",
            "('More', 'JJR')\n",
            "('information', 'NN')\n",
            "('...', ':')\n"
          ]
        }
      ]
    }
  ]
}