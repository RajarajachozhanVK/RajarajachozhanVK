{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGkPskD6QH1f8tlvXPkkSy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RajarajachozhanVK/RajarajachozhanVK/blob/main/N_Grams_for_Word_Document.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **N-Grams for Word Document**\n",
        "1. Learning Objectives\n",
        "\n",
        "    Implement n-gram in Python from scratch and using NLTK\n",
        "\n",
        "    Understand n-grams and their importance\n",
        "\n",
        "    Know the applications of n-grams in NLP\n",
        "\n",
        "    https://www.analyticsvidhya.com/blog/2021/09/what-are-n-grams-and-how-to-implement-them-in-python/\n",
        "\n",
        "2. Language Model\n",
        "\n",
        "    Models that assign probabilities to sequences of words are called language models(LMs).\n",
        "    The simplest language model that assigns probabilities to sentences and sequences of words is the n-gram.\n",
        "\n",
        "3. What is N-Grams(n-grams)?\n",
        "\n",
        "N-grams are continuous sequences of n words or symbols, or tokens extracted from text for language processing and analysis. An n-gram can be as short as a single word (unigram) or as long as multiple words (bigram, trigram, etc.). These n-grams capture the contextual information and relationships between words in a given text.\n",
        "Examples:\n",
        "\n",
        "    Unigrams (1-grams): is a single word sequence of words, e.g., “please” or “ turn” or “cat” or “dog”\n",
        "    Bigrams (2-grams): is a two-word sequence of words, e.g., “natural language” or “deep learning”\n",
        "    Trigrams (3-grams): is a three-word sequence of words, e.g., “machine learning model” or “data science approach”\n",
        "    4-grams, 5-grams, etc.: Sequences of four, five, or more consecutive words.\n",
        "  \n",
        "\n",
        "4. Significance of N-grams in NLP\n",
        "\n",
        "    Capturing Context and Semantics: N-grams help capture the contextual information and semantics within a sequence of words, providing a more nuanced understanding of language.\n",
        "\n",
        "    Improving Language Models: In language modeling tasks, N-grams contribute to building more accurate and context-aware models, enhancing the performance of applications such as machine translation and speech recognition.\n",
        "\n",
        "    Enhancing Text Prediction: N-grams are essential for predictive text applications, aiding in the prediction of the next word or sequence of words based on the context provided by the preceding N-gram.\n",
        "\n",
        "    Information Retrieval: In information retrieval tasks, N-grams assist in matching and ranking documents based on the relevance of N-gram patterns.\n",
        "\n",
        "    Feature Extraction: N-grams serve as powerful features in text classification and sentiment analysis, capturing meaningful patterns that contribute to the characterization of different classes or sentiments.\n",
        "\n",
        "5. Applications of N-grams in NLP\n",
        "\n",
        "N-grams in NLP find applications across a wide range of domains, including:\n",
        "\n",
        "    Sentiment analysis: Analyzing n-grams helps in understanding the sentiment expressed in text by capturing the context of words and phrases.\n",
        "    Named Entity Recognition (NER): NER systems utilize n-grams to identify and classify named entities such as names, locations, organizations, dates, and more.\n",
        "    Text classification: N-grams are used as features in machine learning models for classifying text into predefined categories.\n",
        "    Topic modeling: N-grams aid in uncovering latent topics within a collection of documents, enabling clustering and categorization.\n",
        "    Language generation: N-grams provide the foundation for generating realistic and coherent text, such as in chatbots or language translation systems."
      ],
      "metadata": {
        "id": "A7ELD-t7vWhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPibNTe7wIDP",
        "outputId": "5ad130d8-468a-4612-b756-b9b1ebe0d0f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# An n-gram model is a type of probabilistic language model based on the frequency of n-grams (contiguous sequences of n items) in a given text.\n",
        "from collections import defaultdict\n",
        "from nltk import ngrams\n",
        "# Function to read text from a file\n",
        "def read_text_from_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "# Function to generate n-grams\n",
        "def generate_ngrams(tokens, n):\n",
        "    ngrams_list = ngrams(tokens, n)\n",
        "    return ngrams_list\n",
        "\n",
        "# Function to compute n-gram model\n",
        "def compute_ngram_model(file_path, n):\n",
        "    # Read text from file\n",
        "    text = read_text_from_file(file_path)\n",
        "\n",
        "    # Tokenize the text into words\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "\n",
        "    # Generate n-grams\n",
        "    ngrams_list = generate_ngrams(tokens, n)\n",
        "\n",
        "    # Count the occurrences of each n-gram\n",
        "    ngram_counts = defaultdict(int)\n",
        "    for ngram in ngrams_list:\n",
        "        ngram_counts[ngram] += 1\n",
        "\n",
        "    # Display the n-gram counts\n",
        "    for ngram, count in ngram_counts.items():\n",
        "        print(f\"{ngram}: {count} occurrences\")\n",
        "\n",
        "# Example usage with a file named 'sample.txt' and bigrams (n=2)\n",
        "#file_path = 'sample.txt'\n",
        "file_path = 'ngram_task5.txt'\n",
        "n = 2\n",
        "compute_ngram_model(file_path, n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4rN8OpzxnAT",
        "outputId": "5b0524ae-27e1-4075-99b3-5371c035f959"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('N-grams', 'are'): 1 occurrences\n",
            "('are', 'continuous'): 1 occurrences\n",
            "('continuous', 'sequences'): 1 occurrences\n",
            "('sequences', 'of'): 1 occurrences\n",
            "('of', 'n'): 1 occurrences\n",
            "('n', 'words'): 1 occurrences\n",
            "('words', 'or'): 1 occurrences\n",
            "('or', 'symbols'): 1 occurrences\n",
            "('symbols', ','): 1 occurrences\n",
            "(',', 'or'): 1 occurrences\n",
            "('or', 'tokens'): 1 occurrences\n",
            "('tokens', 'extracted'): 1 occurrences\n",
            "('extracted', 'from'): 1 occurrences\n",
            "('from', 'text'): 1 occurrences\n",
            "('text', 'for'): 1 occurrences\n",
            "('for', 'language'): 1 occurrences\n",
            "('language', 'processing'): 1 occurrences\n",
            "('processing', 'and'): 1 occurrences\n",
            "('and', 'analysis'): 1 occurrences\n",
            "('analysis', '.'): 1 occurrences\n",
            "('.', 'An'): 1 occurrences\n",
            "('An', 'n-gram'): 1 occurrences\n",
            "('n-gram', 'can'): 1 occurrences\n",
            "('can', 'be'): 1 occurrences\n",
            "('be', 'as'): 1 occurrences\n",
            "('as', 'short'): 1 occurrences\n",
            "('short', 'as'): 1 occurrences\n",
            "('as', 'a'): 1 occurrences\n",
            "('a', 'single'): 1 occurrences\n",
            "('single', 'word'): 1 occurrences\n",
            "('word', '('): 1 occurrences\n",
            "('(', 'unigram'): 1 occurrences\n",
            "('unigram', ')'): 1 occurrences\n",
            "(')', 'or'): 1 occurrences\n",
            "('or', 'as'): 1 occurrences\n",
            "('as', 'long'): 1 occurrences\n",
            "('long', 'as'): 1 occurrences\n",
            "('as', 'multiple'): 1 occurrences\n",
            "('multiple', 'words'): 1 occurrences\n",
            "('words', '('): 1 occurrences\n",
            "('(', 'bigram'): 1 occurrences\n",
            "('bigram', ','): 1 occurrences\n",
            "(',', 'trigram'): 1 occurrences\n",
            "('trigram', ','): 1 occurrences\n",
            "(',', 'etc.'): 1 occurrences\n",
            "('etc.', ')'): 1 occurrences\n",
            "(')', '.'): 1 occurrences\n",
            "('.', 'These'): 1 occurrences\n",
            "('These', 'n-grams'): 1 occurrences\n",
            "('n-grams', 'capture'): 1 occurrences\n",
            "('capture', 'the'): 1 occurrences\n",
            "('the', 'contextual'): 1 occurrences\n",
            "('contextual', 'information'): 1 occurrences\n",
            "('information', 'and'): 1 occurrences\n",
            "('and', 'relationships'): 1 occurrences\n",
            "('relationships', 'between'): 1 occurrences\n",
            "('between', 'words'): 1 occurrences\n",
            "('words', 'in'): 1 occurrences\n",
            "('in', 'a'): 1 occurrences\n",
            "('a', 'given'): 1 occurrences\n",
            "('given', 'text'): 1 occurrences\n",
            "('text', '.'): 1 occurrences\n"
          ]
        }
      ]
    }
  ]
}